
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="Learning%20Robust%20Deep%20Visual%20Representations%20from%20EEG%20Brain%20Recordings.html">
      
      
        <link rel="next" href="Reconstructing%20Visual%20Stimulus%20Images%20from%20EEG%20Signals%20Based%20on%20Deep%20Visual%20Representation%20Model.html">
      
      
      <link rel="icon" href="assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.6.17">
    
    
      
        <title>2312.BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction - Brainwaves to Pixels: Notes on EEG-Based Image Reconstruction</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.7e37652d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#brainvis-exploring-the-bridge-between-brain-and-visual-signals-via-image-reconstruction" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="Brainwaves to Pixels: Notes on EEG-Based Image Reconstruction" class="md-header__button md-logo" aria-label="Brainwaves to Pixels: Notes on EEG-Based Image Reconstruction" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Brainwaves to Pixels: Notes on EEG-Based Image Reconstruction
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2312.BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="Brainwaves to Pixels: Notes on EEG-Based Image Reconstruction" class="md-nav__button md-logo" aria-label="Brainwaves to Pixels: Notes on EEG-Based Image Reconstruction" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Brainwaves to Pixels: Notes on EEG-Based Image Reconstruction
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Front page
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="Where%20Does%20EEG%20Come%20From%20and%20What%20Does%20It%20Mean.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Where Does EEG Come From and What Does It Mean
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="%5BSurvey%5DDeep%20Learning%20for%20EEG-Based%20Visual%20Classification%20and%20Reconstruction%5BSEU%5D.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    [Survey]Deep Learning for EEG-Based Visual Classification and Reconstruction[SEU]
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="High-resolution%20image%20reconstruction%20with%20latent%20diffusion%20models%20from%20human%20brain%20activity.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2303.High-resolution image reconstruction with latent diffusion models from human brain activity
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="MindDiffuser-Controlled%20Image%20Reconstruction%20from%20Human%20Brain%20Activity%20with%20Structural%20Diffusion.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2303.MindDiffuser-Controlled Image Reconstruction from Human Brain Activity with Structural Diffusion
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="DreamDiffusion-Generating%20High-Quality%20Images%20from%20Brain%20EEG%20Signals.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2306.DreamDiffusion-Generating High-Quality Images from Brain EEG Signals
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="Seeing%20through%20the%20Brain-Image%20Reconstruction%20of%20Visual%20Perception%20from%20Human%20Brain%20Signals.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2308.Seeing through the Brain-Image Reconstruction of Visual Perception from Human Brain Signals
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="UniBrain-Unify%20Image%20Reconstruction%20and%20Captioning%20in%20One%20Diffusion%20Model%20from%20Brain%20Activity.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2308.UniBrain-Unify Image Reconstruction and Captioning in One Diffusion Model from Brain Activity
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="Decoding%20visual%20brain%20representations%20from%20EEG%20through%20Knowledge%20Distillation%20and%20latent%20diffusion.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2309.Decoding visual brain representations from EEG through Knowledge Distillation and latent diffusion
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="DM-RE2I-A%20framework%20based%20on%20diffusion%20model%20for%20the%20reconstruction%20from%20EEG%20to%20image.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2309.DM-RE2I-A framework based on diffusion model for the reconstruction from EEG to image
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="Learning%20Robust%20Deep%20Visual%20Representations%20from%20EEG%20Brain%20Recordings.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2310.Learning Robust Deep Visual Representations from EEG Brain Recordings
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    2312.BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="BrainVis-Exploring%20the%20Bridge%20between%20Brain%20and%20Visual%20Signals%20via%20Image%20Reconstruction.html" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    2312.BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#info" class="md-nav__link">
    <span class="md-ellipsis">
      üî•INFO
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#motivation" class="md-nav__link">
    <span class="md-ellipsis">
      Motivation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model" class="md-nav__link">
    <span class="md-ellipsis">
      Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pretraining" class="md-nav__link">
    <span class="md-ellipsis">
      Pretraining
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pretraining">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#time-branch" class="md-nav__link">
    <span class="md-ellipsis">
      Time Branch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#frequency-branch" class="md-nav__link">
    <span class="md-ellipsis">
      Frequency Branch
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clip-alignment-finetuing" class="md-nav__link">
    <span class="md-ellipsis">
      CLIP alignment finetuing
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#refined-sd-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Refined SD Generation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#performance" class="md-nav__link">
    <span class="md-ellipsis">
      Performance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ablation" class="md-nav__link">
    <span class="md-ellipsis">
      Ablation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reflections" class="md-nav__link">
    <span class="md-ellipsis">
      üßêReflections
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="Reconstructing%20Visual%20Stimulus%20Images%20from%20EEG%20Signals%20Based%20on%20Deep%20Visual%20Representation%20Model.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2403.Reconstructing Visual Stimulus Images from EEG Signals Based on Deep Visual Representation Model
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="Visual%20Decoding%20and%20Reconstruction%20via%20EEG%20Embeddings%20with%20Guided%20Diffusion.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2403.Visual Decoding and Reconstruction via EEG Embeddings with Guided Diffusion
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="A%20New%20Framework%20Combining%20Diffusion%20and%20Convolution%20Classifier%20for%20Generating%20Images%20from%20EEG%20Signals.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2405.A New Framework Combining Diffusion and Convolution Classifier for Generating Images from EEG Signals
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="MIND%27S%20EYE-IMAGE%20RECOGNITION%20BY%20EEG%20VIA%20MULTIMODAL%20SIMILARITY-KEEPING%20CONTRASTIVE%20LEARNING.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2406.Mind's Eye:Image Recognition by EEG via Multimodal Similarity-Keeping Contrastive Learning
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#info" class="md-nav__link">
    <span class="md-ellipsis">
      üî•INFO
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#motivation" class="md-nav__link">
    <span class="md-ellipsis">
      Motivation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model" class="md-nav__link">
    <span class="md-ellipsis">
      Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pretraining" class="md-nav__link">
    <span class="md-ellipsis">
      Pretraining
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pretraining">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#time-branch" class="md-nav__link">
    <span class="md-ellipsis">
      Time Branch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#frequency-branch" class="md-nav__link">
    <span class="md-ellipsis">
      Frequency Branch
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clip-alignment-finetuing" class="md-nav__link">
    <span class="md-ellipsis">
      CLIP alignment finetuing
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#refined-sd-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Refined SD Generation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#performance" class="md-nav__link">
    <span class="md-ellipsis">
      Performance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ablation" class="md-nav__link">
    <span class="md-ellipsis">
      Ablation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reflections" class="md-nav__link">
    <span class="md-ellipsis">
      üßêReflections
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="brainvis-exploring-the-bridge-between-brain-and-visual-signals-via-image-reconstruction">BrainVis: Exploring the Bridge between Brain and Visual Signals via Image Reconstruction</h1>
<hr />
<h2 id="info">üî•INFO</h2>
<p><strong>Blog</strong>: 2025/07/23 by IgniSavium</p>
<ul>
<li><strong>Title</strong>: BrainVis: Exploring the Bridge between Brain and Visual Signals via Image Reconstruction</li>
<li><strong>Authors</strong>:  Honghao Fu, Hao Wang et.al (HKUST-Guangzhou)</li>
<li><strong>Published</strong>: December 2023</li>
<li><strong>Comment</strong>: BrainVis: Exploring the Bridge between Brain and Visual Signals via Image Reconstruction</li>
<li><strong>URL</strong>: https://arxiv.org/abs/2312.14871</li>
</ul>
<p>ü•ú<strong>TLDR</strong>: This paper introduces <strong>BrainVis</strong>, which reconstructs semantically accurate images from EEG by enhancing representations with (large scale) <strong>self-supervised learning</strong> and CLIP-based alignment.</p>
<hr />
<h2 id="motivation">Motivation</h2>
<p>This paper is motivated by the challenge of reconstructing semantically accurate images from noisy EEG signals‚Äîaddressing limitations of previous methods (i.e. Dream Diffusion) such as weak EEG feature embedding, reliance on large (self-supervision) datasets, and inability to capture fine-grained semantics‚Äîby proposing BrainVis, which enhances EEG representation through <strong>self-supervised learning</strong> (<strong>latent masked modeling</strong>) and <strong>frequency features</strong>, and improves cross-modal alignment with CLIP-based semantic interpolation, achieving superior results with significantly less training data.</p>
<p><img src="BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction.assets\image-20250723175258538.png" alt="image-20250723175258538" style="zoom: 67%;" /></p>
<h2 id="model">Model</h2>
<h3 id="architecture">Architecture</h3>
<p><img alt="image-20250723175333019" src="BrainVis-Exploring%20the%20Bridge%20between%20Brain%20and%20Visual%20Signals%20via%20Image%20Reconstruction.assets/image-20250723175333019.png" /></p>
<p>The main target is to map EEG to conditional text input embeddings in Stable Diffusion.</p>
<h4 id="pretraining">Pretraining</h4>
<h5 id="time-branch">Time Branch</h5>
<p><img src="BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction.assets\image-20250723175638663.png" alt="image-20250723175638663" style="zoom: 80%;" /></p>
<p>The <strong>Latent Masked Modeling (LMM)</strong> pre-training method enhances EEG time-domain feature learning by dividing the signal <span class="arithmatex">\(x \in \mathbb{R}^{c \times l}\)</span> into n units, projecting each into d-dimensional embeddings <span class="arithmatex">\(z \in \mathbb{R}^{n \times d}\)</span>, and applying random masking (ratio <span class="arithmatex">\(r_m\)</span>) for self-supervised learning; the model optimizes two objectives: (1) <strong>regression loss</strong> <span class="arithmatex">\(L_{\text{reg}} = \frac{1}{d} \| f_m - f_{mp} \|^2_2\)</span> to reconstruct masked embeddings using transformer-based predictions, and (2) <strong>classification loss</strong> <span class="arithmatex">\(L_{\text{cls}} = -\mathbf{l}_m \cdot \log(\mathbf{p}_m)\)</span> via codebook tokenization of masked units, with the total loss defined as <span class="arithmatex">\(L_{\text{lmm}} = L_{\text{reg}} + L_{\text{cls}}\)</span>.</p>
<p>(channel = 128, time_step = 440, n = 110, d = 1024, <span class="arithmatex">\(r_M\)</span> = 0.75 and <span class="arithmatex">\(n_{\text{code}}\)</span> = 660)</p>
<p>‚ú®related work: Momentum Encoder ; Vector Quantized VAE</p>
<h5 id="frequency-branch">Frequency Branch</h5>
<ol>
<li><em>Frequency Transformation</em>: EEG signals are converted to the <strong>frequency domain</strong> using <strong>Fast Fourier Transform (FFT)</strong>.</li>
<li><em>Feature Extraction</em>: An <strong>LSTM</strong> model is used to extract frequency features, avoiding overfitting risks of complex networks.</li>
<li><em>Supervised Training</em>: The LSTM is trained with visual <strong>classification</strong> labels using <strong>cross-entropy (CE) loss</strong>.</li>
</ol>
<p><em>Unified Classify</em>: The time and frequency branches are <strong>fine-tuned together</strong> using CE loss to form a unified time-frequency embedding.</p>
<h4 id="clip-alignment-finetuing">CLIP alignment finetuing</h4>
<p>Find a balance (simple sum of loss) between label-induced coarse text feature and description-induced fine text feature. (üßêPossibly tuned together with <em>Unified Classify</em>)</p>
<p><img src="BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction.assets\image-20250723180618459.png" alt="image-20250723180618459" style="zoom: 67%;" /></p>
<h3 id="refined-sd-generation">Refined SD Generation</h3>
<p>Img2Img Refinement using EEG classification labels (inferred from Unified Classify) Ôºàusing only ''label word" as refinement conditional textÔºâ to enhance image quality.</p>
<h2 id="evaluation">Evaluation</h2>
<h3 id="performance">Performance</h3>
<p><img src="BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction.assets\image-20250723220110480.png" alt="image-20250723220110480" style="zoom: 80%;" /></p>
<p><img src="BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction.assets\image-20250723220141330.png" alt="image-20250723220141330" style="zoom: 80%;" /></p>
<p><img src="BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction.assets\image-20250723220233977.png" alt="image-20250723220233977" style="zoom: 80%;" /></p>
<p><img src="BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction.assets\image-20250723220344841.png" alt="image-20250723220344841" style="zoom:80%;" /></p>
<h3 id="ablation">Ablation</h3>
<p>üßêTime Branch is the main information source vs. Frequency Branch.</p>
<p><img src="BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction.assets\image-20250723220553870.png" alt="image-20250723220553870" style="zoom: 80%;" /></p>
<p>üßêSeems that <strong>refinement</strong> (<strong>single-label guided</strong> image2image SD refinement) dominates the output semantics, thus original image structure (size, position, orientation, action etc.) will be largely ignored.</p>
<p><img src="BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction.assets\image-20250723220717787.png" alt="image-20250723220717787" style="zoom: 80%;" /></p>
<p><img src="BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction.assets\image-20250723220739770.png" alt="image-20250723220739770" style="zoom: 80%;" /></p>
<h2 id="reflections">üßêReflections</h2>
<ul>
<li>
<p>There's no experiment to show the effectiveness of MASKED LATENT MODELING <strong>classification objective (codebook design)</strong>.</p>
</li>
<li>
<p>Seems that even simple object class recognition is still a little bit hard for EEG-signal analysisÔºàacc. ~45%Ôºâ compared with fMRI modelingÔºàacc. ~75%Ôºâ .</p>
</li>
</ul>
<p><img src="BrainVis-Exploring the Bridge between Brain and Visual Signals via Image Reconstruction.assets\image-20250723221352104.png" alt="image-20250723221352104" style="zoom: 67%;" /></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/ignisavium" target="_blank" rel="noopener" title="GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": ".", "features": [], "search": "assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="assets/javascripts/bundle.92b07e13.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>